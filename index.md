Mihir Joshi: myjoshi@ucsd.edu
Section - A06; Mentor - Hao Zhang 


**What is the most interesting topic covered in your domain this quarter?**
<br>
The most interesting topic that we have covered in my domain so far is definitely the scaling law and how that is calculated and helps with determining the parameters that we would use for the actual LLM. This is interesting because I didn't originally understand how much trial and error took place during the research process. It is also interesting because small discoveries can have large impacts on how models are trained.

**What other techniques would you be interested in using in your project?**
<br>
I would be interested in looking into techniques on how to make the model training more efficient while maintaining the performance. One aspect that I have been looking into is optimizing the multi-headed attention. For the quarter 2 research project, I will likely look into how changing the focus on the KQV attention leads to differences in performances or where it focuses.
